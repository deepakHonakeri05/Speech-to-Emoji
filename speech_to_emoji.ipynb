{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "nlp-sequence-models",
      "graded_item_id": "RNnEs",
      "launcher_item_id": "acNYU"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "text to emoji.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ6s2BIToiTT",
        "colab_type": "code",
        "outputId": "18cb496d-fdbb-4277-cc44-664e0b877b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSkQ6g8cZ10Q",
        "colab_type": "code",
        "outputId": "de364b47-f37f-40d4-d654-627459383394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 20kB 2.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 30kB 3.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 2.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42175 sha256=5724af1b5d87fc68687214728174e357f9cfea6d8863942d63cc66f66f5fa47e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MpGaj2peFfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from emo_utils import *\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMl0N6LheFft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train = read_csv('/content/drive/My Drive/Project‚Äôs Files/Emojify - AI project/train_emoji.csv')\n",
        "X_test, Y_test = read_csv('/content/drive/My Drive/Project‚Äôs Files/Emojify - AI project/tesss.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xY99gFteFfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxLen = 20\n",
        "#maxLen = len(max(X_train, key=len).split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxXwVPq9eFfz",
        "colab_type": "text"
      },
      "source": [
        "Change `index` below to see different examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5zQ2SOpeFf0",
        "colab_type": "code",
        "outputId": "f5a3f74c-96bc-4de8-ec50-e64668c80e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "index = 99\n",
        "print(X_train[index], label_to_emoji(Y_train[index]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are not qualified for this position üòû\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WltTQSDlq88m"
      },
      "source": [
        "To get our labels into a format suitable for training a softmax classifier, lets convert $Y$ from its current shape  $(m, 1)$ into a \"one-hot representation\" $(m, 5)$, where each row is a one-hot vector giving the label of one example, You can do so using this next code snipper. Here, `Y_oh` stands for \"Y-one-hot\" in the variable names `Y_oh_train` and `Y_oh_test`: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h6DdLziMq8X4",
        "colab": {}
      },
      "source": [
        "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
        "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02TbXJP0eFf9",
        "colab_type": "code",
        "outputId": "995a6bbf-8f18-4c8c-e771-348db11cbc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "index = 50\n",
        "print(Y_train[index], \"is converted into one hot\", Y_oh_train[index])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 is converted into one hot [1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg6f9HX9eFgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/content/drive/My Drive/Project‚Äôs Files/Emojify - AI project/glove.6B.50d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhxnTYieeFgG",
        "colab_type": "text"
      },
      "source": [
        "You've loaded:\n",
        "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
        "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
        "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDrxZWoAeFgI",
        "colab_type": "code",
        "outputId": "739e994d-8756-49e9-8eaf-b98eb15ab53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "word = \"you\"\n",
        "index = 289846\n",
        "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
        "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the index of you in the vocabulary is 394475\n",
            "the 289846th word in the vocabulary is potatos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbfZmvXReFgt",
        "colab_type": "text"
      },
      "source": [
        "## Using LSTMs in Keras: \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhCc2-bqeFgu",
        "colab_type": "code",
        "outputId": "26f1e12e-1198-4199-b96d-0d0b31a1b3a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import glorot_uniform\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2gruz5ieFgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    \"\"\"\n",
        "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
        "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
        "    \n",
        "    Arguments:\n",
        "    X -- array of sentences (strings), of shape (m, 1)\n",
        "    word_to_index -- a dictionary containing the each word mapped to its index\n",
        "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
        "    \n",
        "    Returns:\n",
        "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[0]                                   # number of training examples\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (‚âà 1 line)\n",
        "    X_indices = np.zeros((m,max_len))\n",
        "    \n",
        "    for i in range(m):                               # loop over training examples\n",
        "        \n",
        "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
        "        sentence_words = (X[i].lower()).split()\n",
        "        \n",
        "        # Initialize j to 0\n",
        "        j = 0\n",
        "        \n",
        "        # Loop over the words of sentence_words\n",
        "        for w in sentence_words:\n",
        "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "            X_indices[i, j] = word_to_index[w]\n",
        "            # Increment j to j + 1\n",
        "            j = j+1\n",
        "            \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbkeIffgeFg2",
        "colab_type": "code",
        "outputId": "7f601812-81db-4236-c4ac-d8e26020bf00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
        "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
        "print(\"X1 =\", X1)\n",
        "print(\"X1_indices =\", X1_indices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
            "X1_indices = [[155345. 225122.      0.      0.      0.]\n",
            " [220930. 286375.  69714.      0.      0.]\n",
            " [151204. 192973. 302254. 151349. 394475.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gfjsndzeFg5",
        "colab_type": "text"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **X1 =**\n",
        "        </td>\n",
        "        <td>\n",
        "           ['funny lol' 'lets play baseball' 'food is ready for you']\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **X1_indices =**\n",
        "        </td>\n",
        "        <td>\n",
        "           [[ 155345.  225122.       0.       0.       0.] <br>\n",
        "            [ 220930.  286375.  69714.       0.       0.] <br>\n",
        "            [ 151204.  192973.  302254.  151349.  394475.]]\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y6B2ZNqgsDJS",
        "colab": {}
      },
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    \"\"\"\n",
        "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
        "    \n",
        "    Arguments:\n",
        "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "\n",
        "    Returns:\n",
        "    embedding_layer -- pretrained layer Keras instance\n",
        "    \"\"\"\n",
        "    \n",
        "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
        "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
        "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
        "    \n",
        "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
        "    for word, index in word_to_index.items():\n",
        "        emb_matrix[index, :] = word_to_vec_map[word]\n",
        "\n",
        "    # Define Keras embe i dding layer with the correct output/input sizes, make it non-trainable. Use Embedding(...). Make sure to set trainable=False. \n",
        "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
        "    ### END CODE HERE ##\n",
        "\n",
        "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
        "    embedding_layer.build((None,))\n",
        "    \n",
        "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "    \n",
        "    return embedding_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1f4f8be7-0423-4d3b-a646-c4072b7edc23",
        "id": "9knT0HdPsCup",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2725: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "weights[0][1][3] = -0.3403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA7f_IYCeFhA",
        "colab_type": "text"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **weights[0][1][3] =**\n",
        "        </td>\n",
        "        <td>\n",
        "           -0.3403\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPSFHP0xeFhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
        "    \"\"\"\n",
        "    Function creating the Emojify-v2 model's graph.\n",
        "    \n",
        "    Arguments:\n",
        "    input_shape -- shape of the input, usually (max_len,)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
        "    sentence_indices = Input(input_shape, dtype='int32')\n",
        "    \n",
        "    # Create the embedding layer pretrained with GloVe Vectors (‚âà1 line)\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "    \n",
        "    # Propagate sentence_indices through your embedding layer, you get back the embeddings\n",
        "    embeddings = embedding_layer(sentence_indices)   \n",
        "    \n",
        "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
        "    # Be careful, the returned output should be a batch of sequences.\n",
        "    X = LSTM(128, return_sequences=True)(embeddings)\n",
        "    # Add dropout with a probability of 0.5\n",
        "    #X = Dropout(0.5)(X)\n",
        "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
        "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
        "    X = LSTM(128, return_sequences=False)(X)\n",
        "    # Add dropout with a probability of 0.5\n",
        "    #X = Dropout(0.5)(X)\n",
        "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
        "    X = Dense(5)(X)\n",
        "    # Add a softmax activation\n",
        "    X = Activation('softmax')(X)\n",
        "    \n",
        "    # Create Model instance which converts sentence_indices into X.\n",
        "    model = Model(sentence_indices, X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "_BzeI-MseFhG",
        "colab_type": "code",
        "outputId": "22261d80-8803-427f-d5c7-a6c663fe99ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 20, 50)            20000050  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 20, 128)           91648     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 20,223,927\n",
            "Trainable params: 223,877\n",
            "Non-trainable params: 20,000,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-g8ZaffeFhJ",
        "colab_type": "code",
        "outputId": "ed89a2a0-9532-46de-9b3a-2db5fd2cbf7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzjfWkNweFhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
        "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8Cypb5ozeFhR",
        "colab_type": "code",
        "outputId": "caf2ca43-19a8-4842-f56a-094682e66270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.5523 - acc: 0.8939\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.4260 - acc: 0.9091\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.5408 - acc: 0.8712\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.8256 - acc: 0.8030\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.1863 - acc: 0.9394\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0782 - acc: 0.9773\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.1318 - acc: 0.9621\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.1005 - acc: 0.9621\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0473 - acc: 0.9848\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0550 - acc: 0.9848\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 0s 3ms/step - loss: 0.0469 - acc: 0.9848\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0395 - acc: 0.9848\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0286 - acc: 0.9924\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0212 - acc: 0.9924\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0156 - acc: 0.9924\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0123 - acc: 1.0000\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0096 - acc: 1.0000\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0057 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0050 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0046 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0042 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0013 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac37d5cb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ3Qyu58yoqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/Project‚Äôs Files/Emojify - AI project/model weights/model_82_acc.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-OJXfKTreFhX",
        "colab_type": "code",
        "outputId": "f643337b-0163-41d6-c110-95ac7f2c8cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
        "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
        "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
        "print()\n",
        "print(\"Test accuracy = \", acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 0s 650us/step\n",
            "\n",
            "Test accuracy =  0.8749999914850507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj-9EjFLeFhb",
        "colab_type": "text"
      },
      "source": [
        "## Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qzhtVuBeFhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.  \n",
        "def giveEmo(test):\n",
        "  x_test = np.array([test])\n",
        "  X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "  print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7BEcMwy0fZT",
        "colab_type": "text"
      },
      "source": [
        "## Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIQK1u9g2ga7",
        "colab_type": "code",
        "outputId": "3d1f4857-05a7-46f0-c9cd-7585ed12cdaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        }
      },
      "source": [
        "!pip install SpeechRecognition \n",
        "!sudo apt-get install python-pyaudio python3-pyaudio\n",
        "!pip install ffmpeg-python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SpeechRecognition\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32.8MB 71kB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudio2\n",
            "Suggested packages:\n",
            "  python-pyaudio-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 python-pyaudio python3-pyaudio\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 113 kB of archives.\n",
            "After this operation, 432 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-pyaudio amd64 0.2.11-1build2 [24.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-pyaudio amd64 0.2.11-1build2 [24.2 kB]\n",
            "Fetched 113 kB in 1s (104 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 132684 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package python-pyaudio.\n",
            "Preparing to unpack .../python-pyaudio_0.2.11-1build2_amd64.deb ...\n",
            "Unpacking python-pyaudio (0.2.11-1build2) ...\n",
            "Selecting previously unselected package python3-pyaudio.\n",
            "Preparing to unpack .../python3-pyaudio_0.2.11-1build2_amd64.deb ...\n",
            "Unpacking python3-pyaudio (0.2.11-1build2) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up python-pyaudio (0.2.11-1build2) ...\n",
            "Setting up python3-pyaudio (0.2.11-1build2) ...\n",
            "Collecting ffmpeg-python\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMRAOY4L40Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "import scipy.io.wavfile\n",
        "\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      \n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "  scipy.io.wavfile.write(\"test.wav\",sr, audio)\n",
        "  return audio, sr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzXTM2-Z1z4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def voiceInput():\n",
        "  r = sr.Recognizer()\n",
        "  audio, skl = get_audio()\n",
        "  testAudio = \"./test.wav\"\n",
        "\n",
        "  with sr.AudioFile(testAudio) as source:\n",
        "    audio = r.record(source)  # read the entire audio file\n",
        "    print(\"Speak Anything : \")\n",
        "    try:\n",
        "      text = r.recognize_google(audio)\n",
        "      giveEmo(text)\n",
        "    except:\n",
        "      print(\"Couldn't recognize your voice....speak again\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhKwWFGU5q8P",
        "colab_type": "code",
        "outputId": "06b189e3-f09a-4f6a-ab12-7410beda9c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(audio)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-509ec69b7f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'audio' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mrovmYJAFRJ",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4PaPM9KAK7g",
        "colab_type": "text"
      },
      "source": [
        "### Key input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuJP6OwPAE8b",
        "colab_type": "code",
        "outputId": "b2762d38-5f53-4843-b8ba-601a24e16b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "giveEmo(\"i ate lnch\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-1177d4065d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgiveEmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i ate lnch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-f44f90eff5e1>\u001b[0m in \u001b[0;36mgiveEmo\u001b[0;34m(test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgiveEmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mX_test_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m+\u001b[0m  \u001b[0mlabel_to_emoji\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d9e4c1c939f6>\u001b[0m in \u001b[0;36msentences_to_indices\u001b[0;34m(X, word_to_index, max_len)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Set the (i,j)th entry of X_indices to the index of the correct word.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mX_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Increment j to j + 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'lnch'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdPQ_RWJAOTU",
        "colab_type": "text"
      },
      "source": [
        "### Voice input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVASsPLkAQOg",
        "colab_type": "code",
        "outputId": "8baa90b3-f0e2-4821-e65c-53874e8fe356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "voiceInput()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      \n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Speak Anything : \n",
            "I know I know ‚ù§Ô∏è\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}